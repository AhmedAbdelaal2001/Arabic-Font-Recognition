{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features_from_file(filepath):\n",
    "    data = np.genfromtxt(filepath, delimiter=\",\")\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    return (X, y)\n",
    "\n",
    "# Remove highly correlated features\n",
    "def remove_highly_correlated_features(X, threshold=0.95):\n",
    "    corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    X_reduced = np.delete(X, to_drop, axis=1)\n",
    "    return X_reduced, to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_features_from_file(\"../2. Feature Selection & Extraction/Saved Features/Final_features_training.csv\")\n",
    "X_val, y_val = load_features_from_file(\"../2. Feature Selection & Extraction/Saved Features/Final_features_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.20384\teval-mlogloss:1.22189\n",
      "[1]\ttrain-mlogloss:1.05532\teval-mlogloss:1.08607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttrain-mlogloss:0.93115\teval-mlogloss:0.96972\n",
      "[3]\ttrain-mlogloss:0.82603\teval-mlogloss:0.87144\n",
      "[4]\ttrain-mlogloss:0.73551\teval-mlogloss:0.78684\n",
      "[5]\ttrain-mlogloss:0.65722\teval-mlogloss:0.71370\n",
      "[6]\ttrain-mlogloss:0.58844\teval-mlogloss:0.64939\n",
      "[7]\ttrain-mlogloss:0.52814\teval-mlogloss:0.59295\n",
      "[8]\ttrain-mlogloss:0.47492\teval-mlogloss:0.54174\n",
      "[9]\ttrain-mlogloss:0.42773\teval-mlogloss:0.49605\n",
      "[10]\ttrain-mlogloss:0.38574\teval-mlogloss:0.45629\n",
      "[11]\ttrain-mlogloss:0.34817\teval-mlogloss:0.42038\n",
      "[12]\ttrain-mlogloss:0.31473\teval-mlogloss:0.38829\n",
      "[13]\ttrain-mlogloss:0.28472\teval-mlogloss:0.35965\n",
      "[14]\ttrain-mlogloss:0.25792\teval-mlogloss:0.33373\n",
      "[15]\ttrain-mlogloss:0.23382\teval-mlogloss:0.31081\n",
      "[16]\ttrain-mlogloss:0.21219\teval-mlogloss:0.28998\n",
      "[17]\ttrain-mlogloss:0.19266\teval-mlogloss:0.27037\n",
      "[18]\ttrain-mlogloss:0.17504\teval-mlogloss:0.25215\n",
      "[19]\ttrain-mlogloss:0.15926\teval-mlogloss:0.23655\n",
      "[20]\ttrain-mlogloss:0.14498\teval-mlogloss:0.22173\n",
      "[21]\ttrain-mlogloss:0.13197\teval-mlogloss:0.20767\n",
      "[22]\ttrain-mlogloss:0.12033\teval-mlogloss:0.19502\n",
      "[23]\ttrain-mlogloss:0.10975\teval-mlogloss:0.18348\n",
      "[24]\ttrain-mlogloss:0.10021\teval-mlogloss:0.17348\n",
      "[25]\ttrain-mlogloss:0.09159\teval-mlogloss:0.16453\n",
      "[26]\ttrain-mlogloss:0.08373\teval-mlogloss:0.15595\n",
      "[27]\ttrain-mlogloss:0.07662\teval-mlogloss:0.14857\n",
      "[28]\ttrain-mlogloss:0.07018\teval-mlogloss:0.14110\n",
      "[29]\ttrain-mlogloss:0.06432\teval-mlogloss:0.13446\n",
      "[30]\ttrain-mlogloss:0.05903\teval-mlogloss:0.12812\n",
      "[31]\ttrain-mlogloss:0.05423\teval-mlogloss:0.12224\n",
      "[32]\ttrain-mlogloss:0.04980\teval-mlogloss:0.11724\n",
      "[33]\ttrain-mlogloss:0.04586\teval-mlogloss:0.11282\n",
      "[34]\ttrain-mlogloss:0.04226\teval-mlogloss:0.10800\n",
      "[35]\ttrain-mlogloss:0.03898\teval-mlogloss:0.10397\n",
      "[36]\ttrain-mlogloss:0.03596\teval-mlogloss:0.10016\n",
      "[37]\ttrain-mlogloss:0.03325\teval-mlogloss:0.09646\n",
      "[38]\ttrain-mlogloss:0.03075\teval-mlogloss:0.09330\n",
      "[39]\ttrain-mlogloss:0.02851\teval-mlogloss:0.09037\n",
      "[40]\ttrain-mlogloss:0.02643\teval-mlogloss:0.08719\n",
      "[41]\ttrain-mlogloss:0.02458\teval-mlogloss:0.08487\n",
      "[42]\ttrain-mlogloss:0.02282\teval-mlogloss:0.08207\n",
      "[43]\ttrain-mlogloss:0.02129\teval-mlogloss:0.07996\n",
      "[44]\ttrain-mlogloss:0.01981\teval-mlogloss:0.07763\n",
      "[45]\ttrain-mlogloss:0.01852\teval-mlogloss:0.07591\n",
      "[46]\ttrain-mlogloss:0.01728\teval-mlogloss:0.07407\n",
      "[47]\ttrain-mlogloss:0.01614\teval-mlogloss:0.07239\n",
      "[48]\ttrain-mlogloss:0.01513\teval-mlogloss:0.07091\n",
      "[49]\ttrain-mlogloss:0.01419\teval-mlogloss:0.06965\n",
      "[50]\ttrain-mlogloss:0.01330\teval-mlogloss:0.06821\n",
      "[51]\ttrain-mlogloss:0.01250\teval-mlogloss:0.06678\n",
      "[52]\ttrain-mlogloss:0.01175\teval-mlogloss:0.06560\n",
      "[53]\ttrain-mlogloss:0.01107\teval-mlogloss:0.06463\n",
      "[54]\ttrain-mlogloss:0.01044\teval-mlogloss:0.06345\n",
      "[55]\ttrain-mlogloss:0.00986\teval-mlogloss:0.06226\n",
      "[56]\ttrain-mlogloss:0.00931\teval-mlogloss:0.06127\n",
      "[57]\ttrain-mlogloss:0.00883\teval-mlogloss:0.06061\n",
      "[58]\ttrain-mlogloss:0.00838\teval-mlogloss:0.06021\n",
      "[59]\ttrain-mlogloss:0.00795\teval-mlogloss:0.05914\n",
      "[60]\ttrain-mlogloss:0.00756\teval-mlogloss:0.05859\n",
      "[61]\ttrain-mlogloss:0.00720\teval-mlogloss:0.05780\n",
      "[62]\ttrain-mlogloss:0.00686\teval-mlogloss:0.05715\n",
      "[63]\ttrain-mlogloss:0.00654\teval-mlogloss:0.05638\n",
      "[64]\ttrain-mlogloss:0.00625\teval-mlogloss:0.05582\n",
      "[65]\ttrain-mlogloss:0.00597\teval-mlogloss:0.05525\n",
      "[66]\ttrain-mlogloss:0.00573\teval-mlogloss:0.05482\n",
      "[67]\ttrain-mlogloss:0.00549\teval-mlogloss:0.05447\n",
      "[68]\ttrain-mlogloss:0.00526\teval-mlogloss:0.05421\n",
      "[69]\ttrain-mlogloss:0.00506\teval-mlogloss:0.05367\n",
      "[70]\ttrain-mlogloss:0.00486\teval-mlogloss:0.05344\n",
      "[71]\ttrain-mlogloss:0.00469\teval-mlogloss:0.05300\n",
      "[72]\ttrain-mlogloss:0.00453\teval-mlogloss:0.05250\n",
      "[73]\ttrain-mlogloss:0.00436\teval-mlogloss:0.05234\n",
      "[74]\ttrain-mlogloss:0.00422\teval-mlogloss:0.05199\n",
      "[75]\ttrain-mlogloss:0.00408\teval-mlogloss:0.05176\n",
      "[76]\ttrain-mlogloss:0.00394\teval-mlogloss:0.05163\n",
      "[77]\ttrain-mlogloss:0.00382\teval-mlogloss:0.05140\n",
      "[78]\ttrain-mlogloss:0.00370\teval-mlogloss:0.05109\n",
      "[79]\ttrain-mlogloss:0.00359\teval-mlogloss:0.05092\n",
      "[80]\ttrain-mlogloss:0.00348\teval-mlogloss:0.05046\n",
      "[81]\ttrain-mlogloss:0.00338\teval-mlogloss:0.05026\n",
      "[82]\ttrain-mlogloss:0.00329\teval-mlogloss:0.05019\n",
      "[83]\ttrain-mlogloss:0.00320\teval-mlogloss:0.05006\n",
      "[84]\ttrain-mlogloss:0.00312\teval-mlogloss:0.04998\n",
      "[85]\ttrain-mlogloss:0.00304\teval-mlogloss:0.04975\n",
      "[86]\ttrain-mlogloss:0.00296\teval-mlogloss:0.04951\n",
      "[87]\ttrain-mlogloss:0.00289\teval-mlogloss:0.04958\n",
      "[88]\ttrain-mlogloss:0.00282\teval-mlogloss:0.04942\n",
      "[89]\ttrain-mlogloss:0.00276\teval-mlogloss:0.04933\n",
      "[90]\ttrain-mlogloss:0.00269\teval-mlogloss:0.04900\n",
      "[91]\ttrain-mlogloss:0.00263\teval-mlogloss:0.04904\n",
      "[92]\ttrain-mlogloss:0.00258\teval-mlogloss:0.04889\n",
      "[93]\ttrain-mlogloss:0.00253\teval-mlogloss:0.04866\n",
      "[94]\ttrain-mlogloss:0.00247\teval-mlogloss:0.04840\n",
      "[95]\ttrain-mlogloss:0.00242\teval-mlogloss:0.04837\n",
      "[96]\ttrain-mlogloss:0.00238\teval-mlogloss:0.04818\n",
      "[97]\ttrain-mlogloss:0.00233\teval-mlogloss:0.04826\n",
      "[98]\ttrain-mlogloss:0.00228\teval-mlogloss:0.04823\n",
      "[99]\ttrain-mlogloss:0.00224\teval-mlogloss:0.04797\n",
      "[100]\ttrain-mlogloss:0.00220\teval-mlogloss:0.04807\n",
      "[101]\ttrain-mlogloss:0.00216\teval-mlogloss:0.04798\n",
      "[102]\ttrain-mlogloss:0.00212\teval-mlogloss:0.04785\n",
      "[103]\ttrain-mlogloss:0.00208\teval-mlogloss:0.04766\n",
      "[104]\ttrain-mlogloss:0.00205\teval-mlogloss:0.04771\n",
      "[105]\ttrain-mlogloss:0.00202\teval-mlogloss:0.04777\n",
      "[106]\ttrain-mlogloss:0.00199\teval-mlogloss:0.04767\n",
      "[107]\ttrain-mlogloss:0.00196\teval-mlogloss:0.04769\n",
      "[108]\ttrain-mlogloss:0.00193\teval-mlogloss:0.04758\n",
      "[109]\ttrain-mlogloss:0.00190\teval-mlogloss:0.04752\n",
      "[110]\ttrain-mlogloss:0.00187\teval-mlogloss:0.04745\n",
      "[111]\ttrain-mlogloss:0.00184\teval-mlogloss:0.04731\n",
      "[112]\ttrain-mlogloss:0.00182\teval-mlogloss:0.04718\n",
      "[113]\ttrain-mlogloss:0.00179\teval-mlogloss:0.04706\n",
      "[114]\ttrain-mlogloss:0.00177\teval-mlogloss:0.04705\n",
      "[115]\ttrain-mlogloss:0.00175\teval-mlogloss:0.04695\n",
      "[116]\ttrain-mlogloss:0.00173\teval-mlogloss:0.04681\n",
      "[117]\ttrain-mlogloss:0.00172\teval-mlogloss:0.04672\n",
      "[118]\ttrain-mlogloss:0.00170\teval-mlogloss:0.04663\n",
      "[119]\ttrain-mlogloss:0.00168\teval-mlogloss:0.04653\n",
      "[120]\ttrain-mlogloss:0.00167\teval-mlogloss:0.04659\n",
      "[121]\ttrain-mlogloss:0.00165\teval-mlogloss:0.04644\n",
      "[122]\ttrain-mlogloss:0.00163\teval-mlogloss:0.04630\n",
      "[123]\ttrain-mlogloss:0.00162\teval-mlogloss:0.04615\n",
      "[124]\ttrain-mlogloss:0.00160\teval-mlogloss:0.04607\n",
      "[125]\ttrain-mlogloss:0.00159\teval-mlogloss:0.04610\n",
      "[126]\ttrain-mlogloss:0.00158\teval-mlogloss:0.04588\n",
      "[127]\ttrain-mlogloss:0.00156\teval-mlogloss:0.04587\n",
      "[128]\ttrain-mlogloss:0.00155\teval-mlogloss:0.04578\n",
      "[129]\ttrain-mlogloss:0.00154\teval-mlogloss:0.04568\n",
      "[130]\ttrain-mlogloss:0.00152\teval-mlogloss:0.04556\n",
      "[131]\ttrain-mlogloss:0.00151\teval-mlogloss:0.04542\n",
      "[132]\ttrain-mlogloss:0.00150\teval-mlogloss:0.04538\n",
      "[133]\ttrain-mlogloss:0.00149\teval-mlogloss:0.04537\n",
      "[134]\ttrain-mlogloss:0.00147\teval-mlogloss:0.04523\n",
      "[135]\ttrain-mlogloss:0.00146\teval-mlogloss:0.04501\n",
      "[136]\ttrain-mlogloss:0.00145\teval-mlogloss:0.04503\n",
      "[137]\ttrain-mlogloss:0.00144\teval-mlogloss:0.04503\n",
      "[138]\ttrain-mlogloss:0.00143\teval-mlogloss:0.04491\n",
      "[139]\ttrain-mlogloss:0.00142\teval-mlogloss:0.04489\n",
      "[140]\ttrain-mlogloss:0.00141\teval-mlogloss:0.04484\n",
      "[141]\ttrain-mlogloss:0.00140\teval-mlogloss:0.04483\n",
      "[142]\ttrain-mlogloss:0.00139\teval-mlogloss:0.04489\n",
      "[143]\ttrain-mlogloss:0.00138\teval-mlogloss:0.04483\n",
      "[144]\ttrain-mlogloss:0.00138\teval-mlogloss:0.04475\n",
      "[145]\ttrain-mlogloss:0.00137\teval-mlogloss:0.04478\n",
      "[146]\ttrain-mlogloss:0.00136\teval-mlogloss:0.04467\n",
      "[147]\ttrain-mlogloss:0.00135\teval-mlogloss:0.04463\n",
      "[148]\ttrain-mlogloss:0.00134\teval-mlogloss:0.04456\n",
      "[149]\ttrain-mlogloss:0.00133\teval-mlogloss:0.04457\n",
      "[150]\ttrain-mlogloss:0.00133\teval-mlogloss:0.04459\n",
      "[151]\ttrain-mlogloss:0.00132\teval-mlogloss:0.04449\n",
      "[152]\ttrain-mlogloss:0.00131\teval-mlogloss:0.04442\n",
      "[153]\ttrain-mlogloss:0.00130\teval-mlogloss:0.04439\n",
      "[154]\ttrain-mlogloss:0.00130\teval-mlogloss:0.04433\n",
      "[155]\ttrain-mlogloss:0.00129\teval-mlogloss:0.04431\n",
      "[156]\ttrain-mlogloss:0.00128\teval-mlogloss:0.04423\n",
      "[157]\ttrain-mlogloss:0.00128\teval-mlogloss:0.04421\n",
      "[158]\ttrain-mlogloss:0.00127\teval-mlogloss:0.04430\n",
      "[159]\ttrain-mlogloss:0.00126\teval-mlogloss:0.04430\n",
      "[160]\ttrain-mlogloss:0.00126\teval-mlogloss:0.04425\n",
      "[161]\ttrain-mlogloss:0.00125\teval-mlogloss:0.04416\n",
      "[162]\ttrain-mlogloss:0.00124\teval-mlogloss:0.04412\n",
      "[163]\ttrain-mlogloss:0.00124\teval-mlogloss:0.04407\n",
      "[164]\ttrain-mlogloss:0.00123\teval-mlogloss:0.04407\n",
      "[165]\ttrain-mlogloss:0.00122\teval-mlogloss:0.04411\n",
      "[166]\ttrain-mlogloss:0.00122\teval-mlogloss:0.04402\n",
      "[167]\ttrain-mlogloss:0.00121\teval-mlogloss:0.04408\n",
      "[168]\ttrain-mlogloss:0.00121\teval-mlogloss:0.04405\n",
      "[169]\ttrain-mlogloss:0.00120\teval-mlogloss:0.04398\n",
      "[170]\ttrain-mlogloss:0.00120\teval-mlogloss:0.04391\n",
      "[171]\ttrain-mlogloss:0.00119\teval-mlogloss:0.04390\n",
      "[172]\ttrain-mlogloss:0.00118\teval-mlogloss:0.04387\n",
      "[173]\ttrain-mlogloss:0.00118\teval-mlogloss:0.04387\n",
      "[174]\ttrain-mlogloss:0.00117\teval-mlogloss:0.04377\n",
      "[175]\ttrain-mlogloss:0.00117\teval-mlogloss:0.04372\n",
      "[176]\ttrain-mlogloss:0.00116\teval-mlogloss:0.04368\n",
      "[177]\ttrain-mlogloss:0.00116\teval-mlogloss:0.04375\n",
      "[178]\ttrain-mlogloss:0.00115\teval-mlogloss:0.04372\n",
      "[179]\ttrain-mlogloss:0.00115\teval-mlogloss:0.04371\n",
      "[180]\ttrain-mlogloss:0.00114\teval-mlogloss:0.04369\n",
      "[181]\ttrain-mlogloss:0.00114\teval-mlogloss:0.04373\n",
      "[182]\ttrain-mlogloss:0.00113\teval-mlogloss:0.04364\n",
      "[183]\ttrain-mlogloss:0.00113\teval-mlogloss:0.04362\n",
      "[184]\ttrain-mlogloss:0.00113\teval-mlogloss:0.04365\n",
      "[185]\ttrain-mlogloss:0.00112\teval-mlogloss:0.04367\n",
      "[186]\ttrain-mlogloss:0.00112\teval-mlogloss:0.04362\n",
      "[187]\ttrain-mlogloss:0.00111\teval-mlogloss:0.04362\n",
      "[188]\ttrain-mlogloss:0.00111\teval-mlogloss:0.04351\n",
      "[189]\ttrain-mlogloss:0.00110\teval-mlogloss:0.04343\n",
      "[190]\ttrain-mlogloss:0.00110\teval-mlogloss:0.04340\n",
      "[191]\ttrain-mlogloss:0.00109\teval-mlogloss:0.04336\n",
      "[192]\ttrain-mlogloss:0.00109\teval-mlogloss:0.04341\n",
      "[193]\ttrain-mlogloss:0.00109\teval-mlogloss:0.04346\n",
      "[194]\ttrain-mlogloss:0.00108\teval-mlogloss:0.04341\n",
      "[195]\ttrain-mlogloss:0.00108\teval-mlogloss:0.04344\n",
      "[196]\ttrain-mlogloss:0.00108\teval-mlogloss:0.04338\n",
      "[197]\ttrain-mlogloss:0.00107\teval-mlogloss:0.04337\n",
      "[198]\ttrain-mlogloss:0.00107\teval-mlogloss:0.04335\n",
      "[199]\ttrain-mlogloss:0.00106\teval-mlogloss:0.04333\n",
      "Validation Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Create the DMatrix data structure for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Define the parameters for the XGBoost model\n",
    "params = {\n",
    "    'max_depth': 20,\n",
    "    'eta': 0.1,\n",
    "    'objective': 'multi:softprob',  # Use 'multi:softprob' for multi-class classification\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'num_class': num_classes\n",
    "}\n",
    "\n",
    "# Define the watchlist to track the training and validation error\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 200\n",
    "bst = xgb.train(params, dtrain, num_round, watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_prob = bst.predict(dval)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the SVM model with RBF kernel\n",
    "svm_model = SVC(kernel='linear', C=1, gamma='scale', probability=True)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Random Forest model with additional parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,  # Increase the number of trees\n",
    "    max_depth=10,  # Limit the maximum depth of each tree\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',  # Use the square root of the number of features\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model with additional parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,  # Increase the number of trees\n",
    "    max_depth=10,  # Limit the maximum depth of each tree\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',  # Use the square root of the number of features\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.89018\teval-mlogloss:0.93369\n",
      "[1]\ttrain-mlogloss:0.61980\teval-mlogloss:0.67869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttrain-mlogloss:0.44727\teval-mlogloss:0.51425\n",
      "[3]\ttrain-mlogloss:0.32841\teval-mlogloss:0.39872\n",
      "[4]\ttrain-mlogloss:0.24367\teval-mlogloss:0.31525\n",
      "[5]\ttrain-mlogloss:0.18323\teval-mlogloss:0.25486\n",
      "[6]\ttrain-mlogloss:0.13894\teval-mlogloss:0.20920\n",
      "[7]\ttrain-mlogloss:0.10536\teval-mlogloss:0.17332\n",
      "[8]\ttrain-mlogloss:0.08077\teval-mlogloss:0.14631\n",
      "[9]\ttrain-mlogloss:0.06237\teval-mlogloss:0.12538\n",
      "[10]\ttrain-mlogloss:0.04871\teval-mlogloss:0.11070\n",
      "[11]\ttrain-mlogloss:0.03819\teval-mlogloss:0.09676\n",
      "[12]\ttrain-mlogloss:0.03005\teval-mlogloss:0.08754\n",
      "[13]\ttrain-mlogloss:0.02400\teval-mlogloss:0.07966\n",
      "[14]\ttrain-mlogloss:0.01930\teval-mlogloss:0.07171\n",
      "[15]\ttrain-mlogloss:0.01572\teval-mlogloss:0.06586\n",
      "[16]\ttrain-mlogloss:0.01298\teval-mlogloss:0.06167\n",
      "[17]\ttrain-mlogloss:0.01077\teval-mlogloss:0.05876\n",
      "[18]\ttrain-mlogloss:0.00909\teval-mlogloss:0.05650\n",
      "[19]\ttrain-mlogloss:0.00773\teval-mlogloss:0.05378\n",
      "[20]\ttrain-mlogloss:0.00666\teval-mlogloss:0.05205\n",
      "[21]\ttrain-mlogloss:0.00581\teval-mlogloss:0.05063\n",
      "[22]\ttrain-mlogloss:0.00513\teval-mlogloss:0.04956\n",
      "[23]\ttrain-mlogloss:0.00458\teval-mlogloss:0.04815\n",
      "[24]\ttrain-mlogloss:0.00416\teval-mlogloss:0.04772\n",
      "[25]\ttrain-mlogloss:0.00375\teval-mlogloss:0.04803\n",
      "[26]\ttrain-mlogloss:0.00343\teval-mlogloss:0.04709\n",
      "[27]\ttrain-mlogloss:0.00317\teval-mlogloss:0.04665\n",
      "[28]\ttrain-mlogloss:0.00293\teval-mlogloss:0.04666\n",
      "[29]\ttrain-mlogloss:0.00273\teval-mlogloss:0.04600\n",
      "[30]\ttrain-mlogloss:0.00255\teval-mlogloss:0.04562\n",
      "[31]\ttrain-mlogloss:0.00239\teval-mlogloss:0.04562\n",
      "[32]\ttrain-mlogloss:0.00226\teval-mlogloss:0.04506\n",
      "[33]\ttrain-mlogloss:0.00214\teval-mlogloss:0.04499\n",
      "[34]\ttrain-mlogloss:0.00204\teval-mlogloss:0.04489\n",
      "[35]\ttrain-mlogloss:0.00194\teval-mlogloss:0.04512\n",
      "[36]\ttrain-mlogloss:0.00186\teval-mlogloss:0.04453\n",
      "[37]\ttrain-mlogloss:0.00178\teval-mlogloss:0.04410\n",
      "[38]\ttrain-mlogloss:0.00172\teval-mlogloss:0.04418\n",
      "[39]\ttrain-mlogloss:0.00167\teval-mlogloss:0.04384\n",
      "[40]\ttrain-mlogloss:0.00162\teval-mlogloss:0.04413\n",
      "[41]\ttrain-mlogloss:0.00158\teval-mlogloss:0.04350\n",
      "[42]\ttrain-mlogloss:0.00154\teval-mlogloss:0.04289\n",
      "[43]\ttrain-mlogloss:0.00149\teval-mlogloss:0.04253\n",
      "[44]\ttrain-mlogloss:0.00146\teval-mlogloss:0.04241\n",
      "[45]\ttrain-mlogloss:0.00143\teval-mlogloss:0.04224\n",
      "[46]\ttrain-mlogloss:0.00140\teval-mlogloss:0.04210\n",
      "[47]\ttrain-mlogloss:0.00137\teval-mlogloss:0.04197\n",
      "[48]\ttrain-mlogloss:0.00135\teval-mlogloss:0.04153\n",
      "[49]\ttrain-mlogloss:0.00132\teval-mlogloss:0.04164\n",
      "[50]\ttrain-mlogloss:0.00130\teval-mlogloss:0.04155\n",
      "[51]\ttrain-mlogloss:0.00128\teval-mlogloss:0.04159\n",
      "[52]\ttrain-mlogloss:0.00126\teval-mlogloss:0.04112\n",
      "[53]\ttrain-mlogloss:0.00124\teval-mlogloss:0.04124\n",
      "[54]\ttrain-mlogloss:0.00123\teval-mlogloss:0.04126\n",
      "[55]\ttrain-mlogloss:0.00120\teval-mlogloss:0.04112\n",
      "[56]\ttrain-mlogloss:0.00119\teval-mlogloss:0.04100\n",
      "[57]\ttrain-mlogloss:0.00117\teval-mlogloss:0.04091\n",
      "[58]\ttrain-mlogloss:0.00116\teval-mlogloss:0.04080\n",
      "[59]\ttrain-mlogloss:0.00114\teval-mlogloss:0.04063\n",
      "[60]\ttrain-mlogloss:0.00112\teval-mlogloss:0.04056\n",
      "[61]\ttrain-mlogloss:0.00111\teval-mlogloss:0.04055\n",
      "[62]\ttrain-mlogloss:0.00110\teval-mlogloss:0.04039\n",
      "[63]\ttrain-mlogloss:0.00108\teval-mlogloss:0.04023\n",
      "[64]\ttrain-mlogloss:0.00107\teval-mlogloss:0.04005\n",
      "[65]\ttrain-mlogloss:0.00106\teval-mlogloss:0.04009\n",
      "[66]\ttrain-mlogloss:0.00105\teval-mlogloss:0.04001\n",
      "[67]\ttrain-mlogloss:0.00104\teval-mlogloss:0.04008\n",
      "[68]\ttrain-mlogloss:0.00103\teval-mlogloss:0.04014\n",
      "[69]\ttrain-mlogloss:0.00102\teval-mlogloss:0.04006\n",
      "[70]\ttrain-mlogloss:0.00101\teval-mlogloss:0.04000\n",
      "[71]\ttrain-mlogloss:0.00100\teval-mlogloss:0.03998\n",
      "[72]\ttrain-mlogloss:0.00099\teval-mlogloss:0.03987\n",
      "[73]\ttrain-mlogloss:0.00099\teval-mlogloss:0.03990\n",
      "[74]\ttrain-mlogloss:0.00098\teval-mlogloss:0.03993\n",
      "[75]\ttrain-mlogloss:0.00097\teval-mlogloss:0.03970\n",
      "[76]\ttrain-mlogloss:0.00096\teval-mlogloss:0.03968\n",
      "[77]\ttrain-mlogloss:0.00096\teval-mlogloss:0.03962\n",
      "[78]\ttrain-mlogloss:0.00095\teval-mlogloss:0.03962\n",
      "[79]\ttrain-mlogloss:0.00094\teval-mlogloss:0.03966\n",
      "[80]\ttrain-mlogloss:0.00093\teval-mlogloss:0.03958\n",
      "[81]\ttrain-mlogloss:0.00093\teval-mlogloss:0.03959\n",
      "[82]\ttrain-mlogloss:0.00092\teval-mlogloss:0.03940\n",
      "[83]\ttrain-mlogloss:0.00092\teval-mlogloss:0.03945\n",
      "[84]\ttrain-mlogloss:0.00091\teval-mlogloss:0.03945\n",
      "[85]\ttrain-mlogloss:0.00091\teval-mlogloss:0.03936\n",
      "[86]\ttrain-mlogloss:0.00090\teval-mlogloss:0.03938\n",
      "[87]\ttrain-mlogloss:0.00090\teval-mlogloss:0.03931\n",
      "[88]\ttrain-mlogloss:0.00089\teval-mlogloss:0.03939\n",
      "[89]\ttrain-mlogloss:0.00089\teval-mlogloss:0.03931\n",
      "[90]\ttrain-mlogloss:0.00089\teval-mlogloss:0.03941\n",
      "[91]\ttrain-mlogloss:0.00088\teval-mlogloss:0.03927\n",
      "[92]\ttrain-mlogloss:0.00088\teval-mlogloss:0.03931\n",
      "[93]\ttrain-mlogloss:0.00087\teval-mlogloss:0.03924\n",
      "[94]\ttrain-mlogloss:0.00087\teval-mlogloss:0.03929\n",
      "[95]\ttrain-mlogloss:0.00087\teval-mlogloss:0.03920\n",
      "[96]\ttrain-mlogloss:0.00086\teval-mlogloss:0.03918\n",
      "[97]\ttrain-mlogloss:0.00086\teval-mlogloss:0.03926\n",
      "[98]\ttrain-mlogloss:0.00086\teval-mlogloss:0.03922\n",
      "[99]\ttrain-mlogloss:0.00085\teval-mlogloss:0.03927\n",
      "Validation Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Train the XGBoost model\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "num_classes = len(np.unique(y_train))\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'num_class': num_classes\n",
    "}\n",
    "num_round = 100\n",
    "bst = xgb.train(params, dtrain, num_round, [(dtrain, 'train'), (dval, 'eval')], early_stopping_rounds=10)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1, probability=True))\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions for the validation set\n",
    "y_pred_xgb = bst.predict(dval)\n",
    "y_pred_svm = svm_model.predict_proba(X_val)\n",
    "y_pred_rf = rf_model.predict_proba(X_val)\n",
    "\n",
    "# Combine the predictions (stacking)\n",
    "X_meta = np.hstack((y_pred_xgb, y_pred_svm, y_pred_rf))\n",
    "\n",
    "# Train the meta-model (e.g., Logistic Regression)\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "meta_model.fit(X_meta, y_val)\n",
    "\n",
    "# Make final predictions using the meta-model\n",
    "X_test_meta = np.hstack((\n",
    "    bst.predict(xgb.DMatrix(X_val)),\n",
    "    svm_model.predict_proba(X_val),\n",
    "    rf_model.predict_proba(X_val)\n",
    "))\n",
    "y_pred_meta = meta_model.predict(X_test_meta)\n",
    "\n",
    "# Calculate the accuracy of the stacked model\n",
    "accuracy = accuracy_score(y_val, y_pred_meta)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained KMeans classifier\n",
    "joblib_file = \"svm.pkl\"\n",
    "joblib.dump(svm_model, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
