{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "from GaborExtractor import GaborExtractor\n",
    "from utils import read_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2397\n"
     ]
    }
   ],
   "source": [
    "data, labels = read_processed_data('../Preprocessed Dataset')\n",
    "\n",
    "# Split the data using sklearn's train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "data = 1\n",
    "labels = 1\n",
    "X_test = 1\n",
    "y_test = 1\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Check the size of the training and test sets\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "# print(f\"Validation set size: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the file, assuming no missing values but using genfromtxt for its flexibility\n",
    "data = np.genfromtxt(\"Gabor_features_training.csv\", delimiter=\",\")\n",
    "\n",
    "# Splitting into features and target variable\n",
    "X_train_loaded = data[:, :-1]\n",
    "y_train_loaded = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(y_train == y_train_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "orientations = [k * np.pi / 8 for k in range(1, 9)]\n",
    "frequencies = np.linspace(0.1, 0.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and apply Gabor filters\n",
    "gabor_extractor_training = GaborExtractor()\n",
    "X_train = gabor_extractor_training.extract_gabor_features(X_train, orientations, frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the file in read-binary mode\n",
    "# with open('train_features_32.pkl', 'rb') as file:\n",
    "#     X_train_imported = pickle.load(file)\n",
    "\n",
    "# # Open the file in read-binary mode\n",
    "# with open('test_features_32.pkl', 'rb') as file:\n",
    "#     X_test_imported = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77       602\n",
      "           1       0.90      0.94      0.92       589\n",
      "           2       0.80      0.66      0.73       597\n",
      "           3       0.76      0.82      0.79       609\n",
      "\n",
      "    accuracy                           0.80      2397\n",
      "   macro avg       0.81      0.81      0.80      2397\n",
      "weighted avg       0.81      0.80      0.80      2397\n",
      "\n",
      "Classification Report on LDA:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       602\n",
      "           1       0.99      0.98      0.99       589\n",
      "           2       0.96      0.96      0.96       597\n",
      "           3       0.96      0.96      0.96       609\n",
      "\n",
      "    accuracy                           0.97      2397\n",
      "   macro avg       0.97      0.97      0.97      2397\n",
      "weighted avg       0.97      0.97      0.97      2397\n",
      "\n",
      "Classification Report on QDA:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       602\n",
      "           1       1.00      1.00      1.00       589\n",
      "           2       0.99      0.99      0.99       597\n",
      "           3       1.00      0.99      1.00       609\n",
      "\n",
      "    accuracy                           1.00      2397\n",
      "   macro avg       1.00      1.00      1.00      2397\n",
      "weighted avg       1.00      1.00      1.00      2397\n",
      "\n",
      "Classification Report on SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85       602\n",
      "           1       0.97      0.95      0.96       589\n",
      "           2       0.83      0.79      0.81       597\n",
      "           3       0.79      0.85      0.82       609\n",
      "\n",
      "    accuracy                           0.86      2397\n",
      "   macro avg       0.86      0.86      0.86      2397\n",
      "weighted avg       0.86      0.86      0.86      2397\n",
      "\n",
      "Classification Report on Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       602\n",
      "           1       1.00      1.00      1.00       589\n",
      "           2       1.00      1.00      1.00       597\n",
      "           3       1.00      1.00      1.00       609\n",
      "\n",
      "    accuracy                           1.00      2397\n",
      "   macro avg       1.00      1.00      1.00      2397\n",
      "weighted avg       1.00      1.00      1.00      2397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "    \"SVM\": svm.SVC(kernel='linear'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train and test each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    \n",
    "    # Calculate and print the result statistics\n",
    "    print(f\"Classification Report on {name}:\\n\", classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure y_train is a 2D column vector\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "# Combine the arrays\n",
    "combined_array = np.hstack((X_train, y_train))\n",
    "\n",
    "# Save the combined array to a file\n",
    "np.savetxt(\"Gabor_features_training.csv\", combined_array, delimiter=\",\", fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and apply Gabor filters\n",
    "gabor_extractor_validation = GaborExtractor()\n",
    "X_val = gabor_extractor_validation.extract_gabor_features(X_val, orientations, frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       190\n",
      "           1       0.91      0.98      0.94       201\n",
      "           2       0.80      0.67      0.73       212\n",
      "           3       0.70      0.80      0.75       197\n",
      "\n",
      "    accuracy                           0.79       800\n",
      "   macro avg       0.79      0.79      0.79       800\n",
      "weighted avg       0.79      0.79      0.79       800\n",
      "\n",
      "Classification Report on LDA:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       190\n",
      "           1       1.00      1.00      1.00       201\n",
      "           2       0.91      0.95      0.93       212\n",
      "           3       0.96      0.93      0.94       197\n",
      "\n",
      "    accuracy                           0.96       800\n",
      "   macro avg       0.96      0.96      0.96       800\n",
      "weighted avg       0.96      0.96      0.96       800\n",
      "\n",
      "Classification Report on QDA:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       190\n",
      "           1       0.99      1.00      0.99       201\n",
      "           2       0.93      0.97      0.95       212\n",
      "           3       0.97      0.92      0.95       197\n",
      "\n",
      "    accuracy                           0.96       800\n",
      "   macro avg       0.97      0.96      0.97       800\n",
      "weighted avg       0.97      0.96      0.96       800\n",
      "\n",
      "Classification Report on SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80       190\n",
      "           1       0.97      0.98      0.98       201\n",
      "           2       0.79      0.74      0.77       212\n",
      "           3       0.74      0.83      0.78       197\n",
      "\n",
      "    accuracy                           0.83       800\n",
      "   macro avg       0.83      0.83      0.83       800\n",
      "weighted avg       0.83      0.83      0.83       800\n",
      "\n",
      "Classification Report on Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       190\n",
      "           1       0.88      0.93      0.90       201\n",
      "           2       0.75      0.68      0.71       212\n",
      "           3       0.75      0.78      0.76       197\n",
      "\n",
      "    accuracy                           0.79       800\n",
      "   macro avg       0.78      0.79      0.79       800\n",
      "weighted avg       0.78      0.79      0.78       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and test each classifier\n",
    "for name, clf in classifiers.items():    \n",
    "    # Predict on the training data\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    \n",
    "    # Calculate and print the result statistics\n",
    "    print(f\"Classification Report on {name}:\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure y_train is a 2D column vector\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "# Combine the arrays\n",
    "combined_array = np.hstack((X_val, y_val))\n",
    "\n",
    "# Save the combined array to a file\n",
    "np.savetxt(\"Gabor_features_validation.csv\", combined_array, delimiter=\",\", fmt='%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
